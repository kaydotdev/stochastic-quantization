{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ecb4e08aa6630c",
   "metadata": {},
   "source": [
    "# Training a triplet loss siamese neural network with stochastic quantization model\n",
    "\n",
    "Importing all required third-party dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f8d85223c5bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T18:34:04.466189Z",
     "start_time": "2024-07-24T18:34:02.253742Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "import sq.optim as sq_optim\n",
    "import sq.quantization as sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246c652-d4d7-4ff8-8a7e-7e07aedb3490",
   "metadata": {},
   "source": [
    "Choosing a different algorithm for convolutions computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488839b-343e-4df2-bcf6-226a23e482b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205a84a-d6a0-406f-99f0-696fa01e398c",
   "metadata": {},
   "source": [
    "To enforce reproducibility we set the random seed manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5360a52-1b69-416c-920c-4a89bf75ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Used random seed: {torch.initial_seed()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52589beb-bd71-4264-a05c-a845d6e515a0",
   "metadata": {},
   "source": [
    "We set up the computation device for performing optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e848fc6-13d1-4741-94fd-ed1a9a77880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b775624-0e0c-4658-a826-da9dee689c68",
   "metadata": {},
   "source": [
    "We will use MNIST dataset of handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842f856-65c6-443e-ba54-f8a334b338dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "BATCH_TRAIN = 512\n",
    "BATCH_TEST = 512\n",
    "DATA_DIR = '../../data/'\n",
    "RESULTS_DIR = '../../results/'\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=DATA_DIR, train=True, download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=DATA_DIR, train=False, download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_TEST, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334a278-7fee-4261-9df0-a10f6c2d61f8",
   "metadata": {},
   "source": [
    "These are examples of handwritten digits from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bbf38-5284-4556-9f79-3df92654d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting random samples for the visual showcase\n",
    "row_elements = 5\n",
    "\n",
    "fig, axes = plt.subplots(2, row_elements, figsize=(12, 4))\n",
    "\n",
    "# Display the samples in the image grid\n",
    "for i, (image, label) in enumerate(\n",
    "  itertools.islice(train_dataset, 2 * row_elements)\n",
    "):\n",
    "    row = i // row_elements\n",
    "    col = i % row_elements\n",
    "\n",
    "    axes[row, col].imshow(image.squeeze(), cmap=\"gray\")\n",
    "    axes[row, col].set_title(f\"Element for a class '{label}'\")\n",
    "    axes[row, col].axis(\"off\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf7db0-6139-43b0-bf6f-998485a444f7",
   "metadata": {},
   "source": [
    "A blueprint for a siamese neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e39e63-0c71-4fc7-ae24-09a0df795ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(nn.Module):    \n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(SiameseModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(64 * 7 * 7, 1000),\n",
    "            nn.ELU(),\n",
    "\n",
    "            nn.Linear(1000, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da648ed9-a4b1-49f7-9213-bbd4e1b4be1b",
   "metadata": {},
   "source": [
    "Triplets are mined as semi-hard category in the online mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12995e-8b30-4f30-82b8-c827d4b2a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semihard_triplets(embeddings, labels, margin=1.0):\n",
    "    pairwise_dist = torch.cdist(embeddings, embeddings)\n",
    "\n",
    "    # Create a mask for positive pairs (same label)\n",
    "    labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "    positive_mask = labels_equal.to(embeddings.device)\n",
    "\n",
    "    # Create a mask for negative pairs (different label)\n",
    "    negative_mask = ~positive_mask\n",
    "\n",
    "    # Exclude self-comparisons\n",
    "    mask_no_self = ~torch.eye(embeddings.shape[0], dtype=torch.bool, device=embeddings.device)\n",
    "    positive_mask = positive_mask & mask_no_self\n",
    "    negative_mask = negative_mask & mask_no_self\n",
    "\n",
    "    # Find hardest positive for each anchor\n",
    "    hardest_positive_dist, _ = (pairwise_dist * positive_mask.float()).max(dim=1)\n",
    "\n",
    "    # Find semi-hard negatives for each anchor\n",
    "    semi_hard_negative_mask = (pairwise_dist > hardest_positive_dist.unsqueeze(1)) & \\\n",
    "                              (pairwise_dist < hardest_positive_dist.unsqueeze(1) + margin) & \\\n",
    "                              negative_mask\n",
    "\n",
    "    # If no semi-hard negative exists, use the hardest negative\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        if not semi_hard_negative_mask[i].any():\n",
    "            hard_negative_dist, hard_negative_idx = (pairwise_dist[i] * negative_mask[i].float()).min(dim=0)\n",
    "            semi_hard_negative_mask[i, hard_negative_idx] = True\n",
    "\n",
    "    # Sample triplets\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        positive_indices = torch.where(positive_mask[i])[0]\n",
    "        negative_indices = torch.where(semi_hard_negative_mask[i])[0]\n",
    "\n",
    "        if len(positive_indices) > 0 and len(negative_indices) > 0:\n",
    "            positive_idx = positive_indices[torch.randint(0, len(positive_indices), (1,))]\n",
    "            negative_idx = negative_indices[torch.randint(0, len(negative_indices), (1,))]\n",
    "\n",
    "            anchors.append(embeddings[i])\n",
    "            positives.append(embeddings[positive_idx].squeeze(0))\n",
    "            negatives.append(embeddings[negative_idx].squeeze(0))\n",
    "\n",
    "    return torch.stack(anchors), torch.stack(positives), torch.stack(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a36f8-74f6-4f36-9d87-46c545f0766f",
   "metadata": {},
   "source": [
    "Building an instance of a siamese neural network and training it on a triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e2f50-6a3a-4334-96ec-fbe95c11f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "TRIPLETS_MARGIN = 1.0\n",
    "\n",
    "siamese_model = SiameseModel(latent_dim=LATENT_DIM).to(device)\n",
    "criterion = nn.TripletMarginLoss(margin=TRIPLETS_MARGIN, p=2)\n",
    "optimizer = optim.Adam(siamese_model.parameters(), lr=1e-3, weight_decay=1e-05)\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_train_loss = []\n",
    "    epoch_val_loss = []\n",
    "\n",
    "    # Training loss and accuracy\n",
    "    siamese_model.train()\n",
    "\n",
    "    for images, labels in (progress_bar := tqdm(train_dataloader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = siamese_model(images)\n",
    "        loss = criterion(*get_semihard_triplets(output, labels, margin=TRIPLETS_MARGIN))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss.append(loss.item())\n",
    "        progress_bar.set_description(f\"Train loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss.append(np.mean(np.array(epoch_train_loss)))\n",
    "\n",
    "    # Validation loss and accuracy\n",
    "    siamese_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = siamese_model(images)\n",
    "            loss = criterion(*get_semihard_triplets(output, labels))\n",
    "\n",
    "            epoch_val_loss.append(loss.item())\n",
    "\n",
    "    val_loss.append(np.mean(np.array(epoch_val_loss)))\n",
    "\n",
    "    print(f\"Validation loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051f5f4-4d16-4f1d-b9f1-e9e6e257fcbd",
   "metadata": {},
   "source": [
    "We compare train and validation losses to detect the overfitting of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31d087-a3fd-4a1a-ad1a-95ce9e493431",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6), tight_layout=True)\n",
    "\n",
    "ax.plot(range(len(train_loss)), train_loss, linestyle='-',\n",
    "           marker='o', color='k', markersize=4, label=\"Train loss\")\n",
    "ax.plot(range(len(val_loss)), val_loss, linestyle='--',\n",
    "           marker='s', color='k', markersize=4, label=\"Validation loss\")\n",
    "\n",
    "ax.set_title(\"Train and validation loss with each epoch\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend(loc=\"upper center\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e871d8-0606-49d1-b5ef-160a496f7840",
   "metadata": {},
   "source": [
    "We convert all handwritten digits from the dataset to visualize their embeddings in the metric space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9d201-7577-4ece-aadb-2ef591fbc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_embeddings_by_label(model: nn.Module, dataloader: DataLoader):\n",
    "    all_embeddings = np.empty((0, LATENT_DIM))\n",
    "    grouped_embeddings = {i: np.empty((0, LATENT_DIM)) for i in range(10)}\n",
    "\n",
    "    for img, lbs in dataloader:\n",
    "        model_device = next(model.parameters()).device\n",
    "        batch_embeddings = model(img.to(model_device))\n",
    "        batch_embeddings = batch_embeddings.cpu().detach().numpy()\n",
    "\n",
    "        lbs = lbs.detach().numpy()\n",
    "\n",
    "        for emb, lb in zip(batch_embeddings, lbs):\n",
    "            grouped_embeddings[lb] = np.vstack((grouped_embeddings[lb], np.array(emb)))\n",
    "\n",
    "    for cl, embeds in grouped_embeddings.items():\n",
    "        all_embeddings = np.vstack((all_embeddings, np.array(embeds)))\n",
    "\n",
    "    return grouped_embeddings, all_embeddings\n",
    "\n",
    "\n",
    "embedding_model = siamese_model.encoder\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_group_embeds, train_all_embeds = group_embeddings_by_label(embedding_model, train_dataloader)\n",
    "    test_group_embeds, test_all_embeds = group_embeddings_by_label(embedding_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fea23-6855-48ac-9bad-7a3882fb0994",
   "metadata": {},
   "source": [
    "If our latent space has a dimensionality greater than 3, we use PCA to project embeddings on a 3D plane, while trying to preserve an original distribution as much as possible with 90% of variance. As train data embeddings are positioned similarly to the test embeddings, we can assume that encoder learned low-level prepresentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41cc93-5912-4293-93b8-4a2d6d7312d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, embeds_dim = train_all_embeds.shape\n",
    "\n",
    "if embeds_dim > 3:\n",
    "    pca = PCA(n_components=3, random_state=RANDOM_SEED).fit(train_all_embeds)\n",
    "\n",
    "    train_viz_embeds = {cl: pca.transform(embeds) for cl, embeds in train_group_embeds.items()}\n",
    "    test_viz_embeds = {cl: pca.transform(embeds) for cl, embeds in test_group_embeds.items()}\n",
    "else:\n",
    "    train_viz_embeds = train_group_embeds\n",
    "    test_viz_embeds = test_group_embeds\n",
    "\n",
    "markers = ['o', '^', 's', 'p', '*', 'x', 'D', 'v', 'h', '+']\n",
    "markers_color = mpl.colormaps['gray'].resampled(len(markers))\n",
    "markers_color_range = np.linspace(0.2, 0.8, len(markers))\n",
    "\n",
    "markevery, marksize = 50, 10\n",
    "elev, azim = 21, 100\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.view_init(elev=elev, azim=azim, roll=0)\n",
    "\n",
    "for idx, (cls, embeds) in enumerate(train_viz_embeds.items()):\n",
    "    subset_embeds = embeds[::markevery]\n",
    "    cls_color = markers_color(markers_color_range[idx])\n",
    "\n",
    "    ax.scatter3D(subset_embeds[:, 0], subset_embeds[:, 1], subset_embeds[:, 2], color=cls_color,\n",
    "                 label=cls, alpha=1.0, s=marksize, marker=markers[idx % len(markers)])\n",
    "\n",
    "ax.legend(loc=\"upper center\", ncol=5)\n",
    "ax.set_title(r'Train dataset embeddings with $ \\frac{1}{50} $ density')\n",
    "\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_xlim((-7.5, 7.5))\n",
    "\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_ylim((-7.5, 7.5))\n",
    "\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_zlim((-7.5, 7.5))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.view_init(elev=elev, azim=azim, roll=0)\n",
    "\n",
    "for idx, (cls, embeds) in enumerate(test_viz_embeds.items()):\n",
    "    subset_embeds = embeds[::markevery]\n",
    "    cls_color = markers_color(markers_color_range[idx])\n",
    "\n",
    "    ax.scatter3D(subset_embeds[:, 0], subset_embeds[:, 1], subset_embeds[:, 2], color=cls_color,\n",
    "                 label=cls, alpha=1.0, s=marksize, marker=markers[idx % len(markers)])\n",
    "\n",
    "ax.legend(loc=\"upper center\", ncol=5)\n",
    "ax.set_title(r'Test dataset embeddings with $ \\frac{1}{50} $ density')\n",
    "\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_xlim((-7.5, 7.5))\n",
    "\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_ylim((-7.5, 7.5))\n",
    "\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_zlim((-7.5, 7.5))\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60ca08-ec10-406f-9256-2a6e526c75eb",
   "metadata": {},
   "source": [
    "We will use stochastic quantization algorithm for the non-convex optimization problem of representations clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356e796-fabc-4b23-9dbe-495b23552bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQ_ITERS = 15\n",
    "\n",
    "sq_algorithms = {\n",
    "    \"SGD\": sq.StochasticQuantization(sq_optim.SGDOptimizer(), n_clusters=10, max_iter=SQ_ITERS,\n",
    "                                     random_state=np.random.RandomState(RANDOM_SEED)),\n",
    "    \"Momentum\": sq.StochasticQuantization(sq_optim.MomentumOptimizer(), n_clusters=10, max_iter=SQ_ITERS,\n",
    "                                          learning_rate=0.001, random_state=np.random.RandomState(RANDOM_SEED)),\n",
    "    \"NAG\": sq.StochasticQuantization(sq_optim.NAGOptimizer(), n_clusters=10, max_iter=SQ_ITERS,\n",
    "                                     learning_rate=0.001, random_state=np.random.RandomState(RANDOM_SEED)),\n",
    "    \"Adagrad\": sq.StochasticQuantization(sq_optim.AdagradOptimizer(), n_clusters=10, max_iter=SQ_ITERS,\n",
    "                                         learning_rate=0.5, random_state=np.random.RandomState(RANDOM_SEED)),\n",
    "    \"RMSProp\": sq.StochasticQuantization(sq_optim.RMSPropOptimizer(), n_clusters=10, max_iter=SQ_ITERS,\n",
    "                                         random_state=np.random.RandomState(RANDOM_SEED)),\n",
    "    \"Adam\": sq.StochasticQuantization(sq_optim.AdamOptimizer(), n_clusters=10, max_iter=SQ_ITERS,\n",
    "                                      learning_rate=0.01, random_state=np.random.RandomState(RANDOM_SEED))\n",
    "}\n",
    "\n",
    "markers = [('o', '-'), ('s', '--'), ('^', ':'), ('d', '-.'), ('p', (0, (5, 5))), ('h', (0, (1, 1)))]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "for idx, (name, alg) in enumerate(sq_algorithms.items()):\n",
    "    marker, linestyle = markers[idx % len(markers)]\n",
    "\n",
    "    alg = alg.fit(train_all_embeds)\n",
    "\n",
    "    ax.plot(range(len(alg.loss_history_)), alg.loss_history_,\n",
    "            linestyle=linestyle, marker=marker, color='k',\n",
    "            markersize=4, label=name)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.title(\"Convergence rate of each quantization algorithm\")\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Objective function loss')\n",
    "plt.legend(loc=\"upper center\", ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d6ddb-8d0a-447b-b439-ae85b4829e2f",
   "metadata": {},
   "source": [
    "We use confusion matrix to compare the accuracy of classification model for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f43ff-c89a-4f13-8235-3f9cafc4140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col, n_row = (2, 3)\n",
    "fig, ax = plt.subplots(n_col, n_row, figsize=(12, 8))\n",
    "f1_scores = {}\n",
    "\n",
    "for idx, (name, alg) in enumerate(sq_algorithms.items()):\n",
    "    y_true, y_pred = np.array([]), np.array([])\n",
    "\n",
    "    for _, embs in test_group_embeds.items():\n",
    "        cls = alg.predict(embs)\n",
    "        cls_predicted = np.bincount(cls).argmax()\n",
    "\n",
    "        y_true = np.append(y_true, np.full((1, len(embs)), cls_predicted))\n",
    "        y_pred = np.append(y_pred, cls)\n",
    "\n",
    "    ax_idx = ax[idx // n_row, idx % n_row]\n",
    "\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true, y_pred, cmap=\"Greys\", colorbar=False, ax=ax_idx\n",
    "    )\n",
    "\n",
    "    ax_idx.set_title(f\"Confusion matrix of a DEC with {name}\")\n",
    "    f1_scores[name] = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76ac7f-6b1f-4dfd-bd30-1b79aca83182",
   "metadata": {},
   "source": [
    "To account for label imbalance in the test set, we choose a weighted F1 score as an accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2956763-1dfa-4828-b850-43b2891ac985",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "bars = ax.bar(f1_scores.keys(), f1_scores.values(), color='k')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2.0,\n",
    "            height, f'{round(height, 4)}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_xlabel(\"Algorithm\")\n",
    "ax.set_ylabel(\"F1 score\")\n",
    "ax.set_title(\"Comparing accuracy of each stochastic quantization modification\")\n",
    "ax.set_ylim(top=1.1)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca64807-d07b-4b23-836e-7f41388604e3",
   "metadata": {},
   "source": [
    "Save encoder model for the later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7534f28-18f1-44c3-8630-02f59d5f9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(RESULTS_DIR, \"model\")\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "embedding_model.eval()\n",
    "\n",
    "torch.save(embedding_model.state_dict(), os.path.join(MODEL_DIR, \"siamese_model.bin\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
